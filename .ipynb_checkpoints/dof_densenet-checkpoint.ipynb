{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dont overfit DenseNet implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Details\n",
    "#### Link: https://www.kaggle.com/c/dont-overfit-ii\n",
    "#### Best DenseNet Result: 0.675 accuracy\n",
    "#### Epoch: 200\n",
    "#### Batch Size: 32\n",
    "#### Depth: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Input, Flatten, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training and test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 20, 15, 1)\n",
      "(19750, 20, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "f = open('dataset/train.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "\n",
    "train_array = []\n",
    "train_label = []\n",
    "\n",
    "ctr = 0\n",
    "for row in reader:\n",
    "    if(ctr):\n",
    "        train_label.append(int(float(row[1])))\n",
    "        row.pop(0)\n",
    "        row.pop(0)\n",
    "        # print(len(row))\n",
    "        train_array.append([float(i) for i in row])\n",
    "        # break\n",
    "    ctr += 1\n",
    "f.close()\n",
    "\n",
    "x_train = np.asarray(train_array)\n",
    "y_train = np.asarray(train_label)\n",
    "\n",
    "x_cnn_train = x_train.reshape(250,20,15,1)\n",
    "y_cnn_train = y_train\n",
    "\n",
    "\n",
    "print(x_cnn_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "f = open('dataset/test.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "\n",
    "test_array = []\n",
    "test_label = []\n",
    "\n",
    "ctr = 0\n",
    "for row in reader:\n",
    "    if(ctr):\n",
    "        test_label.append(int(float(row[0])))\n",
    "        row.pop(0)\n",
    "        test_array.append([float(i) for i in row])\n",
    "    ctr += 1\n",
    "f.close()\n",
    "\n",
    "x_test = np.asarray(test_array)\n",
    "y_test = np.asarray(test_label)\n",
    "\n",
    "x_cnn_test = x_test.reshape(19750,20,15,1)\n",
    "y_cnn_test = y_test\n",
    "\n",
    "print(x_cnn_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_cnn_train.shape[1:]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "num_classes = 1\n",
    "num_dense_blocks = 3\n",
    "# use_max_pool = False\n",
    "\n",
    "growth_rate = 12\n",
    "depth = 100\n",
    "num_bottleneck_layers = (depth - 4) // (2 * num_dense_blocks)\n",
    "\n",
    "num_filters_bef_dense_block = 2 * growth_rate\n",
    "compression_factor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\randy\\Anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\randy\\Anaconda3\\envs\\DL\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20, 15, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 20, 15, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20, 15, 1)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 15, 24)   240         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 15, 25)   0           input_1[0][0]                    \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 20, 15, 25)   100         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20, 15, 25)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 20, 15, 48)   1248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 15, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 15, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 20, 15, 48)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 20, 15, 12)   5196        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 15, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 20, 15, 37)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 20, 15, 37)   148         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 20, 15, 37)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 20, 15, 48)   1824        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 20, 15, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 20, 15, 48)   192         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 20, 15, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 20, 15, 12)   5196        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 20, 15, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 20, 15, 49)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 20, 15, 49)   196         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 20, 15, 49)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 20, 15, 48)   2400        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20, 15, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 20, 15, 48)   192         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 20, 15, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 20, 15, 12)   5196        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 20, 15, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 20, 15, 61)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 20, 15, 61)   244         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 20, 15, 61)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 20, 15, 48)   2976        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 20, 15, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 20, 15, 48)   192         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 20, 15, 48)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 20, 15, 12)   5196        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20, 15, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 20, 15, 73)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 20, 15, 73)   292         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 20, 15, 73)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 15, 48)   3552        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20, 15, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 20, 15, 48)   192         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 20, 15, 48)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 20, 15, 12)   5196        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 20, 15, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 20, 15, 85)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 20, 15, 85)   340         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 20, 15, 85)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 20, 15, 48)   4128        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 20, 15, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 20, 15, 48)   192         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 20, 15, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 20, 15, 12)   5196        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 20, 15, 12)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 20, 15, 97)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 20, 15, 97)   388         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 20, 15, 97)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 20, 15, 48)   4704        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 20, 15, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 20, 15, 48)   192         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 20, 15, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 20, 15, 12)   5196        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 20, 15, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 20, 15, 109)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 20, 15, 109)  436         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 20, 15, 109)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 20, 15, 48)   5280        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 20, 15, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 20, 15, 48)   192         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 20, 15, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 20, 15, 12)   5196        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 20, 15, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 20, 15, 121)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 20, 15, 121)  484         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 20, 15, 121)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 20, 15, 48)   5856        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 20, 15, 48)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 20, 15, 48)   192         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 20, 15, 48)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 20, 15, 12)   5196        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 20, 15, 12)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 20, 15, 133)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 20, 15, 133)  532         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 20, 15, 133)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 20, 15, 48)   6432        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 20, 15, 48)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 20, 15, 48)   192         dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 20, 15, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 20, 15, 12)   5196        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 20, 15, 12)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 20, 15, 145)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 20, 15, 145)  580         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 20, 15, 145)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 20, 15, 48)   7008        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 20, 15, 48)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 20, 15, 48)   192         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 20, 15, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 20, 15, 12)   5196        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 20, 15, 12)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 20, 15, 157)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 20, 15, 157)  628         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 20, 15, 157)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 20, 15, 48)   7584        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 20, 15, 48)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 20, 15, 48)   192         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 20, 15, 48)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 20, 15, 12)   5196        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 20, 15, 12)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 20, 15, 169)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 20, 15, 169)  676         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 20, 15, 169)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 20, 15, 48)   8160        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 20, 15, 48)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 20, 15, 48)   192         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 20, 15, 48)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 20, 15, 12)   5196        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 20, 15, 12)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 20, 15, 181)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 20, 15, 181)  724         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 20, 15, 181)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 20, 15, 48)   8736        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 20, 15, 48)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 20, 15, 48)   192         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 20, 15, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 20, 15, 12)   5196        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 20, 15, 12)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 20, 15, 193)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 20, 15, 193)  772         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 20, 15, 193)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 20, 15, 48)   9312        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 20, 15, 48)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 20, 15, 48)   192         dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 20, 15, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 20, 15, 12)   5196        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 20, 15, 12)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 20, 15, 205)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 20, 15, 205)  820         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 20, 15, 205)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 20, 15, 48)   9888        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 20, 15, 48)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 20, 15, 48)   192         dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 20, 15, 48)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 20, 15, 12)   5196        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 20, 15, 12)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 20, 15, 217)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 20, 15, 217)  868         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 20, 15, 108)  23544       batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 20, 15, 108)  0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 10, 7, 108)   0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 10, 7, 108)   432         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 10, 7, 108)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 10, 7, 48)    5232        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 10, 7, 48)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 10, 7, 48)    192         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 10, 7, 48)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 10, 7, 12)    5196        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 10, 7, 12)    0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 10, 7, 120)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 10, 7, 120)   480         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 10, 7, 120)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 10, 7, 48)    5808        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 10, 7, 48)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 10, 7, 48)    192         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 10, 7, 48)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 10, 7, 12)    5196        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 10, 7, 12)    0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 10, 7, 132)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 10, 7, 132)   528         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 10, 7, 132)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 10, 7, 48)    6384        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 10, 7, 48)    0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 7, 48)    192         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 10, 7, 48)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 10, 7, 12)    5196        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 10, 7, 12)    0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 10, 7, 144)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 10, 7, 144)   576         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 10, 7, 144)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 10, 7, 48)    6960        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 10, 7, 48)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 10, 7, 48)    192         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 10, 7, 48)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 10, 7, 12)    5196        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 10, 7, 12)    0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 10, 7, 156)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 10, 7, 156)   624         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 10, 7, 156)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 10, 7, 48)    7536        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 10, 7, 48)    0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 10, 7, 48)    192         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 10, 7, 48)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 10, 7, 12)    5196        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 10, 7, 12)    0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 10, 7, 168)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 10, 7, 168)   672         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 10, 7, 168)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 10, 7, 48)    8112        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 10, 7, 48)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 10, 7, 48)    192         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 10, 7, 48)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 10, 7, 12)    5196        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 10, 7, 12)    0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 10, 7, 180)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 10, 7, 180)   720         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 10, 7, 180)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 10, 7, 48)    8688        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 10, 7, 48)    0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 10, 7, 48)    192         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 10, 7, 48)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 10, 7, 12)    5196        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 10, 7, 12)    0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 10, 7, 192)   0           concatenate_23[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 10, 7, 192)   768         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 10, 7, 192)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 10, 7, 48)    9264        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 10, 7, 48)    0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 7, 48)    192         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 10, 7, 48)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 10, 7, 12)    5196        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 10, 7, 12)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 10, 7, 204)   0           concatenate_24[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 10, 7, 204)   816         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 10, 7, 204)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 10, 7, 48)    9840        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 10, 7, 48)    0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 10, 7, 48)    192         dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 10, 7, 48)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 10, 7, 12)    5196        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 10, 7, 12)    0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 10, 7, 216)   0           concatenate_25[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 10, 7, 216)   864         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 10, 7, 216)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 10, 7, 48)    10416       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 10, 7, 48)    0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 10, 7, 48)    192         dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 10, 7, 48)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 10, 7, 12)    5196        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 10, 7, 12)    0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 10, 7, 228)   0           concatenate_26[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 10, 7, 228)   912         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 10, 7, 228)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 10, 7, 48)    10992       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 10, 7, 48)    0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 10, 7, 48)    192         dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 10, 7, 48)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 10, 7, 12)    5196        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 10, 7, 12)    0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 10, 7, 240)   0           concatenate_27[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 10, 7, 240)   960         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 10, 7, 240)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 10, 7, 48)    11568       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 10, 7, 48)    0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 10, 7, 48)    192         dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 10, 7, 48)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 10, 7, 12)    5196        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 10, 7, 12)    0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 10, 7, 252)   0           concatenate_28[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 10, 7, 252)   1008        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 10, 7, 252)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 10, 7, 48)    12144       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 10, 7, 48)    0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 7, 48)    192         dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 10, 7, 48)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 10, 7, 12)    5196        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 10, 7, 12)    0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 10, 7, 264)   0           concatenate_29[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 10, 7, 264)   1056        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 10, 7, 264)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 10, 7, 48)    12720       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 10, 7, 48)    0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 10, 7, 48)    192         dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 10, 7, 48)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 10, 7, 12)    5196        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 10, 7, 12)    0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 10, 7, 276)   0           concatenate_30[0][0]             \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 10, 7, 276)   1104        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 10, 7, 276)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 10, 7, 48)    13296       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 10, 7, 48)    0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 10, 7, 48)    192         dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 10, 7, 48)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 10, 7, 12)    5196        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 10, 7, 12)    0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 10, 7, 288)   0           concatenate_31[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 10, 7, 288)   1152        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 10, 7, 288)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 10, 7, 48)    13872       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 10, 7, 48)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 10, 7, 48)    192         dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 10, 7, 48)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 10, 7, 12)    5196        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 10, 7, 12)    0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 10, 7, 300)   0           concatenate_32[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 10, 7, 300)   1200        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 10, 7, 150)   45150       batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 10, 7, 150)   0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 5, 3, 150)    0           dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 5, 3, 150)    600         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 5, 3, 150)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 5, 3, 48)     7248        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 5, 3, 48)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 5, 3, 48)     192         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 5, 3, 48)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 5, 3, 12)     5196        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 5, 3, 12)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 5, 3, 162)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 5, 3, 162)    648         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 5, 3, 162)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 5, 3, 48)     7824        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 5, 3, 48)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 3, 48)     192         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 5, 3, 48)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 3, 12)     5196        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 5, 3, 12)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 5, 3, 174)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 3, 174)    696         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 5, 3, 174)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 3, 48)     8400        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 5, 3, 48)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 5, 3, 48)     192         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 3, 48)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 5, 3, 12)     5196        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 5, 3, 12)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 5, 3, 186)    0           concatenate_35[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 5, 3, 186)    744         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 3, 186)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 5, 3, 48)     8976        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 5, 3, 48)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 3, 48)     192         dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 5, 3, 48)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 3, 12)     5196        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 5, 3, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 5, 3, 198)    0           concatenate_36[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 3, 198)    792         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 5, 3, 198)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 3, 48)     9552        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 5, 3, 48)     0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 3, 48)     192         dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 3, 48)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 3, 12)     5196        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 5, 3, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 5, 3, 210)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 3, 210)    840         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 3, 210)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 3, 48)     10128       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 5, 3, 48)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 3, 48)     192         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 3, 48)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 3, 12)     5196        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 5, 3, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 5, 3, 222)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 3, 222)    888         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 3, 222)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 3, 48)     10704       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 5, 3, 48)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 3, 48)     192         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 3, 48)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 3, 12)     5196        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 5, 3, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 5, 3, 234)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 3, 234)    936         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 3, 234)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 3, 48)     11280       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 5, 3, 48)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 3, 48)     192         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 3, 48)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 3, 12)     5196        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 5, 3, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 5, 3, 246)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 3, 246)    984         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 3, 246)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 3, 48)     11856       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 5, 3, 48)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 3, 48)     192         dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 3, 48)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 3, 12)     5196        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 5, 3, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 5, 3, 258)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 3, 258)    1032        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 3, 258)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 3, 48)     12432       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 5, 3, 48)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 3, 48)     192         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 3, 48)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 3, 12)     5196        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 5, 3, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 5, 3, 270)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 3, 270)    1080        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 3, 270)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 3, 48)     13008       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 5, 3, 48)     0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 3, 48)     192         dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 3, 48)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 3, 12)     5196        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 5, 3, 12)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 5, 3, 282)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 3, 282)    1128        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 3, 282)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 3, 48)     13584       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 5, 3, 48)     0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 3, 48)     192         dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 3, 48)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 3, 12)     5196        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 5, 3, 12)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 5, 3, 294)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 3, 294)    1176        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 3, 294)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 3, 48)     14160       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 5, 3, 48)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 3, 48)     192         dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 3, 48)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 3, 12)     5196        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 5, 3, 12)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 5, 3, 306)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 3, 306)    1224        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 3, 306)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 3, 48)     14736       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 5, 3, 48)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 5, 3, 48)     192         dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 3, 48)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 5, 3, 12)     5196        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 5, 3, 12)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 5, 3, 318)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 5, 3, 318)    1272        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 3, 318)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 5, 3, 48)     15312       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 5, 3, 48)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 5, 3, 48)     192         dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 5, 3, 48)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 5, 3, 12)     5196        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 5, 3, 12)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 5, 3, 330)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 5, 3, 330)    1320        concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 5, 3, 330)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 5, 3, 48)     15888       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 5, 3, 48)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 5, 3, 48)     192         dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 5, 3, 48)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 5, 3, 12)     5196        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 5, 3, 12)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 5, 3, 342)    0           concatenate_48[0][0]             \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 1, 342)    0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 684)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            685         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 792,715\n",
      "Trainable params: 769,375\n",
      "Non-trainable params: 23,340\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(num_filters_bef_dense_block,\n",
    "           kernel_size=3,\n",
    "           padding='same',\n",
    "           kernel_initializer='he_normal')(x)\n",
    "x = concatenate([inputs, x])\n",
    "\n",
    "# stack of dense blocks bridged by transition layers\n",
    "for i in range(num_dense_blocks):\n",
    "    # a dense block is a stack of bottleneck layers\n",
    "    for j in range(num_bottleneck_layers):\n",
    "        y = BatchNormalization()(x)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(4 * growth_rate,\n",
    "                   kernel_size=1,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(y)\n",
    "        \n",
    "        y = Dropout(0.2)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(growth_rate,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(y)\n",
    "        \n",
    "        y = Dropout(0.2)(y)\n",
    "        x = concatenate([x, y])\n",
    "\n",
    "    # no transition layer after the last dense block\n",
    "    if i == num_dense_blocks - 1:\n",
    "        continue\n",
    "\n",
    "    # transition layer compresses num of feature maps and reduces the size by 2\n",
    "    num_filters_bef_dense_block += num_bottleneck_layers * growth_rate\n",
    "    num_filters_bef_dense_block = int(num_filters_bef_dense_block * compression_factor)\n",
    "    y = BatchNormalization()(x)\n",
    "    y = Conv2D(num_filters_bef_dense_block,\n",
    "               kernel_size=1,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal')(y)\n",
    "    \n",
    "    y = Dropout(0.2)(y)  \n",
    "    x = AveragePooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "x = AveragePooling2D(pool_size=2)(x)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(num_classes,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='sigmoid')(y)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'binary_crossentropy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\randy\\Anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.9498 - acc: 0.5480 - binary_crossentropy: 0.9498\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7716 - acc: 0.5600 - binary_crossentropy: 0.7716\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6702 - acc: 0.6120 - binary_crossentropy: 0.6702\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6702 - acc: 0.6320 - binary_crossentropy: 0.6702\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6449 - acc: 0.6240 - binary_crossentropy: 0.6449\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6502 - acc: 0.6360 - binary_crossentropy: 0.6502\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6112 - acc: 0.6960 - binary_crossentropy: 0.6112\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6211 - acc: 0.6480 - binary_crossentropy: 0.6211\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6247 - acc: 0.6400 - binary_crossentropy: 0.6247\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5990 - acc: 0.6920 - binary_crossentropy: 0.5990\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5897 - acc: 0.6880 - binary_crossentropy: 0.5897\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5636 - acc: 0.6920 - binary_crossentropy: 0.5636\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5868 - acc: 0.6960 - binary_crossentropy: 0.5868\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5992 - acc: 0.6640 - binary_crossentropy: 0.5992\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5478 - acc: 0.7040 - binary_crossentropy: 0.5478\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5221 - acc: 0.7240 - binary_crossentropy: 0.5221\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5406 - acc: 0.7320 - binary_crossentropy: 0.5406\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4761 - acc: 0.7960 - binary_crossentropy: 0.4761\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4860 - acc: 0.7640 - binary_crossentropy: 0.4860\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4448 - acc: 0.8160 - binary_crossentropy: 0.4448\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4588 - acc: 0.7920 - binary_crossentropy: 0.4588\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4278 - acc: 0.7800 - binary_crossentropy: 0.4278\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4202 - acc: 0.8200 - binary_crossentropy: 0.4202\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4016 - acc: 0.8200 - binary_crossentropy: 0.4016\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3933 - acc: 0.8160 - binary_crossentropy: 0.3933\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3823 - acc: 0.8200 - binary_crossentropy: 0.3823\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3621 - acc: 0.8240 - binary_crossentropy: 0.3621\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3482 - acc: 0.8720 - binary_crossentropy: 0.3482\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2950 - acc: 0.8760 - binary_crossentropy: 0.2950\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2992 - acc: 0.8880 - binary_crossentropy: 0.2992\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2480 - acc: 0.8960 - binary_crossentropy: 0.2480\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2193 - acc: 0.9120 - binary_crossentropy: 0.2193\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2143 - acc: 0.9240 - binary_crossentropy: 0.2143\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2143 - acc: 0.9320 - binary_crossentropy: 0.2143\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2119 - acc: 0.9000 - binary_crossentropy: 0.2119\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1671 - acc: 0.9400 - binary_crossentropy: 0.1671\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1628 - acc: 0.9400 - binary_crossentropy: 0.1628\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1707 - acc: 0.9360 - binary_crossentropy: 0.1707\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1405 - acc: 0.9480 - binary_crossentropy: 0.1405\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1953 - acc: 0.9120 - binary_crossentropy: 0.1953\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1175 - acc: 0.9680 - binary_crossentropy: 0.1175\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1134 - acc: 0.9680 - binary_crossentropy: 0.1134\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1166 - acc: 0.9480 - binary_crossentropy: 0.1166\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0846 - acc: 0.9680 - binary_crossentropy: 0.0846\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1136 - acc: 0.9480 - binary_crossentropy: 0.1136\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1567 - acc: 0.9280 - binary_crossentropy: 0.1567\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0836 - acc: 0.9680 - binary_crossentropy: 0.0836\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0804 - acc: 0.9840 - binary_crossentropy: 0.0804\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0696 - acc: 0.9800 - binary_crossentropy: 0.0696\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0626 - acc: 0.9800 - binary_crossentropy: 0.0626\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0575 - acc: 0.9840 - binary_crossentropy: 0.0575\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0370 - acc: 0.9840 - binary_crossentropy: 0.0370\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0784 - acc: 0.9760 - binary_crossentropy: 0.0784\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0704 - acc: 0.9720 - binary_crossentropy: 0.0704\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0750 - acc: 0.9640 - binary_crossentropy: 0.0750\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0686 - acc: 0.9720 - binary_crossentropy: 0.0686\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0643 - acc: 0.9720 - binary_crossentropy: 0.0643\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0385 - acc: 0.9920 - binary_crossentropy: 0.0385\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0477 - acc: 0.9800 - binary_crossentropy: 0.0477\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0454 - acc: 0.9840 - binary_crossentropy: 0.0454\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0305 - acc: 0.9880 - binary_crossentropy: 0.0305\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0318 - acc: 0.9920 - binary_crossentropy: 0.0318\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0259 - acc: 0.9880 - binary_crossentropy: 0.0259\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0331 - acc: 0.9880 - binary_crossentropy: 0.0331\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0285 - acc: 0.9920 - binary_crossentropy: 0.0285\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0289 - acc: 0.9920 - binary_crossentropy: 0.0289\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0184 - acc: 0.9960 - binary_crossentropy: 0.0184\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0179 - acc: 0.9960 - binary_crossentropy: 0.0179\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0323 - acc: 0.9960 - binary_crossentropy: 0.0323\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0332 - acc: 0.9920 - binary_crossentropy: 0.0332\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0329 - acc: 0.9840 - binary_crossentropy: 0.0329\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0548 - acc: 0.9880 - binary_crossentropy: 0.0548\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0357 - acc: 0.9840 - binary_crossentropy: 0.0357\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0201 - acc: 1.0000 - binary_crossentropy: 0.0201\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0162 - acc: 0.9960 - binary_crossentropy: 0.0162\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0242 - acc: 0.9880 - binary_crossentropy: 0.0242\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0087 - acc: 1.0000 - binary_crossentropy: 0.0087\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0358 - acc: 0.9880 - binary_crossentropy: 0.0358\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0198 - acc: 0.9960 - binary_crossentropy: 0.0198\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0105 - acc: 1.0000 - binary_crossentropy: 0.0105\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0117 - acc: 0.9960 - binary_crossentropy: 0.0117\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0208 - acc: 0.9960 - binary_crossentropy: 0.0208\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0125 - acc: 1.0000 - binary_crossentropy: 0.0125\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0388 - acc: 0.9800 - binary_crossentropy: 0.0388\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0503 - acc: 0.9760 - binary_crossentropy: 0.0503\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0731 - acc: 0.9880 - binary_crossentropy: 0.0731\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0375 - acc: 0.9840 - binary_crossentropy: 0.0375\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0297 - acc: 0.9800 - binary_crossentropy: 0.0297\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0227 - acc: 0.9960 - binary_crossentropy: 0.0227\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0254 - acc: 0.9880 - binary_crossentropy: 0.0254\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0099 - acc: 1.0000 - binary_crossentropy: 0.0099\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0266 - acc: 0.9880 - binary_crossentropy: 0.0266\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0121 - acc: 0.9960 - binary_crossentropy: 0.0121\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0184 - acc: 0.9960 - binary_crossentropy: 0.0184\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0177 - acc: 0.9960 - binary_crossentropy: 0.0177\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0142 - acc: 0.9960 - binary_crossentropy: 0.0142\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0258 - acc: 0.9920 - binary_crossentropy: 0.0258\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0112 - acc: 0.9960 - binary_crossentropy: 0.0112\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0037 - acc: 1.0000 - binary_crossentropy: 0.0037\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0189 - acc: 0.9880 - binary_crossentropy: 0.0189\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0050 - acc: 1.0000 - binary_crossentropy: 0.0050\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0057 - acc: 1.0000 - binary_crossentropy: 0.0057\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0144 - acc: 0.9960 - binary_crossentropy: 0.0144\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0266 - acc: 0.9920 - binary_crossentropy: 0.0266\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0092 - acc: 0.9960 - binary_crossentropy: 0.0092\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0098 - acc: 1.0000 - binary_crossentropy: 0.0098\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0230 - acc: 0.9920 - binary_crossentropy: 0.0230\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0123 - acc: 0.9920 - binary_crossentropy: 0.0123\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0130 - acc: 0.9960 - binary_crossentropy: 0.0130\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0143 - acc: 0.9960 - binary_crossentropy: 0.0143\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0056 - acc: 1.0000 - binary_crossentropy: 0.0056\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0077 - acc: 1.0000 - binary_crossentropy: 0.0077\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0147 - acc: 0.9960 - binary_crossentropy: 0.0147\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0118 - acc: 0.9960 - binary_crossentropy: 0.0118\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0243 - acc: 0.9920 - binary_crossentropy: 0.0243\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0124 - acc: 0.9960 - binary_crossentropy: 0.0124\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0113 - acc: 0.9960 - binary_crossentropy: 0.0113\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0258 - acc: 0.9920 - binary_crossentropy: 0.0258\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0101 - acc: 0.9960 - binary_crossentropy: 0.0101\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0125 - acc: 0.9960 - binary_crossentropy: 0.0125\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0134 - acc: 0.9880 - binary_crossentropy: 0.0134\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0061 - acc: 1.0000 - binary_crossentropy: 0.0061\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0077 - acc: 0.9960 - binary_crossentropy: 0.0077\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0339 - acc: 0.9960 - binary_crossentropy: 0.0339\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0098 - acc: 0.9960 - binary_crossentropy: 0.0098\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0124 - acc: 0.9960 - binary_crossentropy: 0.0124\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0160 - acc: 0.9920 - binary_crossentropy: 0.0160\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0059 - acc: 0.9960 - binary_crossentropy: 0.0059\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0071 - acc: 0.9960 - binary_crossentropy: 0.0071\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0071 - acc: 1.0000 - binary_crossentropy: 0.0071\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0075 - acc: 1.0000 - binary_crossentropy: 0.0075\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0049 - acc: 0.9960 - binary_crossentropy: 0.0049\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0045 - acc: 1.0000 - binary_crossentropy: 0.0045\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0108 - acc: 0.9960 - binary_crossentropy: 0.0108\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0033 - acc: 1.0000 - binary_crossentropy: 0.0033\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0213 - acc: 0.9960 - binary_crossentropy: 0.0213\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0076 - acc: 0.9960 - binary_crossentropy: 0.0076\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0028 - acc: 1.0000 - binary_crossentropy: 0.0028\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0025 - acc: 1.0000 - binary_crossentropy: 0.0025\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0039 - acc: 1.0000 - binary_crossentropy: 0.0039\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 1.0000 - binary_crossentropy: 0.0015\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0017 - acc: 1.0000 - binary_crossentropy: 0.0017 \n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0072 - acc: 0.9960 - binary_crossentropy: 0.0072\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0057 - acc: 0.9960 - binary_crossentropy: 0.0057  \n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0068 - acc: 0.9960 - binary_crossentropy: 0.0068 \n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0043 - acc: 1.0000 - binary_crossentropy: 0.0043\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0166 - acc: 0.9960 - binary_crossentropy: 0.0166\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 7.6153e-04 - acc: 1.0000 - binary_crossentropy: 7.6153e-04\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0026 - acc: 1.0000 - binary_crossentropy: 0.0026\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 1.0000 - binary_crossentropy: 0.0015  \n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0012 - acc: 1.0000 - binary_crossentropy: 0.0012    \n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0057 - acc: 0.9960 - binary_crossentropy: 0.0057\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0073 - acc: 0.9960 - binary_crossentropy: 0.0073\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0012 - acc: 1.0000 - binary_crossentropy: 0.0012 \n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0104 - acc: 0.9920 - binary_crossentropy: 0.0104\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0027 - acc: 1.0000 - binary_crossentropy: 0.0027\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0062 - acc: 0.9960 - binary_crossentropy: 0.0062\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0199 - acc: 0.9920 - binary_crossentropy: 0.0199\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0102 - acc: 0.9960 - binary_crossentropy: 0.0102  \n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0228 - acc: 0.9880 - binary_crossentropy: 0.0228\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0080 - acc: 0.9960 - binary_crossentropy: 0.0080\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0081 - acc: 0.9960 - binary_crossentropy: 0.0081\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0109 - acc: 0.9960 - binary_crossentropy: 0.0109\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0137 - acc: 0.9960 - binary_crossentropy: 0.0137\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0147 - acc: 0.9920 - binary_crossentropy: 0.0147\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0012 - acc: 1.0000 - binary_crossentropy: 0.0012 \n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0085 - acc: 1.0000 - binary_crossentropy: 0.0085\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0053 - acc: 1.0000 - binary_crossentropy: 0.0053\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0103 - acc: 0.9920 - binary_crossentropy: 0.0103\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0195 - acc: 0.9920 - binary_crossentropy: 0.0195\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0280 - acc: 0.9880 - binary_crossentropy: 0.0280\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0109 - acc: 0.9960 - binary_crossentropy: 0.0109\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0264 - acc: 0.9920 - binary_crossentropy: 0.0264\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0823 - acc: 0.9760 - binary_crossentropy: 0.0823\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0527 - acc: 0.9880 - binary_crossentropy: 0.0527\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0583 - acc: 0.9760 - binary_crossentropy: 0.0583\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0167 - acc: 0.9880 - binary_crossentropy: 0.0167\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0167 - acc: 0.9920 - binary_crossentropy: 0.0167\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0376 - acc: 0.9880 - binary_crossentropy: 0.0376\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0132 - acc: 0.9920 - binary_crossentropy: 0.0132\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0214 - acc: 0.9840 - binary_crossentropy: 0.0214\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0476 - acc: 0.9840 - binary_crossentropy: 0.0476\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0137 - acc: 0.9960 - binary_crossentropy: 0.0137\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0058 - acc: 1.0000 - binary_crossentropy: 0.0058\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0058 - acc: 0.9960 - binary_crossentropy: 0.0058\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0069 - acc: 1.0000 - binary_crossentropy: 0.0069\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0201 - acc: 0.9920 - binary_crossentropy: 0.0201\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0102 - acc: 0.9960 - binary_crossentropy: 0.0102\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0042 - acc: 1.0000 - binary_crossentropy: 0.0042\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 1.0000 - binary_crossentropy: 0.0015\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0095 - acc: 1.0000 - binary_crossentropy: 0.0095\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0096 - acc: 0.9960 - binary_crossentropy: 0.0096\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0043 - acc: 1.0000 - binary_crossentropy: 0.0043\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0061 - acc: 0.9960 - binary_crossentropy: 0.0061\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0037 - acc: 1.0000 - binary_crossentropy: 0.0037\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 1.0000 - binary_crossentropy: 0.0015 \n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0151 - acc: 0.9960 - binary_crossentropy: 0.0151\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0034 - acc: 1.0000 - binary_crossentropy: 0.0034\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0104 - acc: 0.9960 - binary_crossentropy: 0.0104\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 1.0000 - binary_crossentropy: 0.0018  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1862288ba20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_cnn_train, y_cnn_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model on Test Data and generate CSV file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "filename='DenseNET_D'+str(depth)+'_BS'+str(batch_size)+'_E'+str(epochs)+'.csv'\n",
    "\n",
    "res = model.predict(x_cnn_test)\n",
    "\n",
    "with open('submissions/'+filename, \"w\",  newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(('id', 'target'))\n",
    "        for (x, y) in zip(y_test, res):\n",
    "            if y[0] >= 0.5:\n",
    "                targ = 1\n",
    "            else:\n",
    "                targ = 0\n",
    "            writer.writerow((x,targ))\n",
    "            \n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
